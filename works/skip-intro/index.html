<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Victor Bitca">
<meta name="description" content="If you ever binge-watched a series you should already be familiar with the urge to skip ASAP that intro/outro song.
Many streaming services already have a skip intro button, but how does it work? Did you think that the content partners need to specify timestamps for intro/outros at the content ingest stage? That would be too easy.
I attempted to automate the intro detection with chromaprint mostly for fun because it seems that was my definition of fun at the time." />
<meta name="keywords" content=", golang, chromaprint, audio fingerprinting" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://3am.engineering/works/skip-intro/" />


    <title>
        
            Skip that intro! :: 3am engineering 
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="/main.min.5bfb908ea0e9e0fa4f7e8016a36896c5e4f71b49cc913f137c1c0f6b4dda0525.css">




<meta itemprop="name" content="Skip that intro!">
<meta itemprop="description" content="If you ever binge-watched a series you should already be familiar with the urge to skip ASAP that intro/outro song.
Many streaming services already have a skip intro button, but how does it work? Did you think that the content partners need to specify timestamps for intro/outros at the content ingest stage? That would be too easy.
I attempted to automate the intro detection with chromaprint mostly for fun because it seems that was my definition of fun at the time."><meta itemprop="datePublished" content="2019-04-19T00:00:00+00:00" />
<meta itemprop="dateModified" content="2019-04-19T00:00:00+00:00" />
<meta itemprop="wordCount" content="750">
<meta itemprop="keywords" content="golang,chromaprint,audio fingerprinting," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Skip that intro!"/>
<meta name="twitter:description" content="If you ever binge-watched a series you should already be familiar with the urge to skip ASAP that intro/outro song.
Many streaming services already have a skip intro button, but how does it work? Did you think that the content partners need to specify timestamps for intro/outros at the content ingest stage? That would be too easy.
I attempted to automate the intro detection with chromaprint mostly for fun because it seems that was my definition of fun at the time."/>





    <meta property="article:published_time" content="2019-04-19 00:00:00 &#43;0000 UTC" />








    </head>

    <body class="dark-theme">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__text">3am engineering</span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://3am.engineering/about/">About</a></li><li><a href="https://3am.engineering/works/">Works</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://3am.engineering/works/skip-intro/">Skip that intro!</a></h2>

            

            <div class="post-content">
                <p>If you ever binge-watched a series you should already be familiar with the urge to skip ASAP that intro/outro song.</p>
<p>Many streaming services already have a skip intro button, but how does it work?
Did you think that the content partners need to specify timestamps for intro/outros at the content ingest stage? That would be too easy.</p>
<p>I attempted to automate the intro detection with <code>chromaprint</code> mostly for fun because it seems that was my definition of fun at the time.</p>
<p>First thing, install the workhorse of the industry <a href="https://ffmpeg.org/"><code>ffmpeg</code></a> to do some work on the video files themselves and <code>golang</code> <a href="https://github.com/go-fingerprint/">wrappers</a> for <a href="https://acoustid.org/chromaprint">chromaprint</a></p>
<h2 id="preparation-phase">Preparation phase</h2>
<p>Let&rsquo;s say I got hold of some JoJo&rsquo;s Bizarre Adventure episodes.
First, I need to strip the audio from the video files, using <code>ffmpeg</code> is fast and it looks like this in my case.</p>
<p>Strip the audio stream: <code>ffmpeg -i input.mkv -vn -c:a copy output.m4a</code></p>
<p>Next, I&rsquo;ll need to uncompress it into a .wav file also drop as many bytes as possible, making it mono and trimming it to first 3 minutes where usually the intro song plays should be good enough.</p>
<p>Convert to .wav: <code>ffmpeg -i output.m4a output.wav</code></p>
<p>Convert stereo .wav to mono .wav: <code>ffmpeg -I output.wav -ac 1 m_output.wav</code></p>
<p>Trim down to 180 seconds: <code>ffmpeg -i m_output.wav -af atrim=0:180 m_t_output.wav</code></p>
<p>Yes, it can be automated with a bash script, but I needed to do for like ten files&hellip; I should&rsquo;ve written a script.</p>
<h2 id="finding-the-common-region">Finding the common region</h2>
<p>By running a piece of raw audio data (a .wav file with no header) through chromaprint you get the fingerprints of those files which are actually just spectrograms, <a href="https://oxygene.sk/2011/01/how-does-chromaprint-work/">more info on how it works</a>.</p>
<figure><img src="/images/ep2wav.jpg"
         alt="Typical output for a 3min .wav file"/><figcaption>
            <p>Typical output for a 3min .wav file</p>
        </figcaption>
</figure>

<p>Comparing two perfectly aligned audio files results in this image.
The black area at the beginning is where the spectrograms <code>XOR</code>-ed perfectly resulting mostly in a black area.</p>
<figure><img src="/images/2min-diff.jpg"
         alt="Comparing first 2min of two episodes"/><figcaption>
            <p>Comparing first 2min of two episodes</p>
        </figcaption>
</figure>

<p>But in some cases, most of the cases actually intros aren&rsquo;t aligned perfectly, before the intro song begins there could be some scenes from previous episodes or some pre-intro scenes from the current episode.
Those scenes always vary in length and if I were to compare the spectrograms it would look like a bunch of noise.</p>
<p>One way to find the common areas on two different spectrograms is to slide them past each other like a puzzle each iteration resulting in a match score.
I start with an 50% offset between the slices (<a href="https://blog.golang.org/go-slices-usage-and-internals">golang view of an array</a>) and end on -50% offset, good enough for the intro I&rsquo;m searching, each time the offset decreases the slices get actually a bit bigger then again smaller (highlighted in blue).
Another way could be using the &ldquo;Longest Common Substring&rdquo; approach with some tolerance between values but that&rsquo;s for another time.</p>
<p>After all the slide and compare action, I&rsquo;ll pick the iteration with the best score and do a comparison, usually resulting in something like the picture above.</p>
<figure><img src="/images/match-search.jpg"
         alt="Initial state - incremental sliding and comparing two fingerprints"/><figcaption>
            <p>Initial state - incremental sliding and comparing two fingerprints</p>
        </figcaption>
</figure>

<p>By the way, raw fingerprints of those two files are just <code>int32</code> slices, images above are just for visual aid and the <code>int32</code> values are one-pixel width vertical slices from each fingerprint.
The comparison between the values is done using <a href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a> for each pair of <code>int32</code> values.</p>
<p>Once I compared the best match I get a similar result but with more numbers:</p>
<p><code>[15, 20, 9, 13, 12, 10, 6, 7, 3, 2, 2, 1, 0, 3, 2, 1, 9, 13, 12, 14]</code></p>
<p>Each value is the Hamming distance between two <code>int32</code> pairs and its easy to spot somewhere in the middle there is a subsequence that gets below 10 and sits there for quite a while.
That is the matching area I was looking for, If I were to compare those fingerprints and output an image it would have a blacker area somewhere in the middle, next step is to calculate how long it is, then taking into account the offset it is trivial to calculate where the intro song started and ended for both files.</p>
<figure><img src="/images/matcher_demo.gif"
         alt="Searching for intro in 10 files (single threaded)"/><figcaption>
            <p>Searching for intro in 10 files (single threaded)</p>
        </figcaption>
</figure>

<h2 id="conclusion">Conclusion</h2>
<p>The result is a robust way to find common regions/fingerprints in two or more audio files, at least in this concrete use case.</p>
<p>The implementation can be seen <a href="https://github.com/VictorBitca/matcher"><code>here</code></a>.
Disclaimer: The solution is in no way perfect, probably not written in an idiomatic <code>golang</code> style since it was one of the first <code>golang</code> projects that was actually of any use.</p>

            </div>
        </article>

        <hr />

        <div class="post-info">
  				<p>
  					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://3am.engineering/tags/golang">golang</a></span><span class="tag"><a href="https://3am.engineering/tags/chromaprint">chromaprint</a></span><span class="tag"><a href="https://3am.engineering/tags/audio-fingerprinting">audio fingerprinting</a></span>
  				</p>
  			</div>

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2021</span>
            
                <span><a href="https://3am.engineering/">3am engineering</a></span>
            
        </div>
    </div>
</footer>

            
        </div>

        




<script type="text/javascript" src="/bundle.min.08ccaf9cef8b4e0ebd0b0158e66a7bfc0ddbb2194cdb0099e8814ddb89cc7628b27b1158846564e6e03d9ffc5f4d1bc7dfc274d359f9408d1c63d73a3f7332e9.js" integrity="sha512-CMyvnO&#43;LTg69CwFY5mp7/A3bshlM2wCZ6IFN24nMdiiyexFYhGVk5uA9n/xfTRvH38J001n5QI0cY9c6P3My6Q=="></script>



    </body>
</html>
